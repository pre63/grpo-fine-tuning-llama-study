{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "from scipy.stats import f_oneway\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import chi2_contingency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "dataset_name = \"cais/hle\"\n",
    "hf_split = \"test\"\n",
    "domain_col = \"category\"  # Adjust if needed\n",
    "test_size = 0.3  # 30% for evaluation\n",
    "min_count_per_domain = 50  # Minimum samples per domain for sufficiency check\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load dataset\n",
    "dataset = load_dataset(dataset_name, split=hf_split)\n",
    "df = pd.DataFrame(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# Z-test function (as previously provided)\n",
    "def z_test_p_value(sample_mean, population_mean, population_std, sample_size, alternative='two-sided'):\n",
    "    z = (sample_mean - population_mean) / (population_std / math.sqrt(sample_size))\n",
    "    if alternative == 'two-sided':\n",
    "        p_value = 2 * (1 - norm.cdf(abs(z)))\n",
    "    elif alternative == 'greater':\n",
    "        p_value = 1 - norm.cdf(z)\n",
    "    elif alternative == 'less':\n",
    "        p_value = norm.cdf(z)\n",
    "    else:\n",
    "        raise ValueError(\"Alternative must be one of ['two-sided', 'greater', 'less']\")\n",
    "    \n",
    "    return p_value\n",
    "\n",
    "# Function to flag outliers using Z-test\n",
    "def detect_outliers_z(data, population_mean, population_std, threshold=0.05):\n",
    "    sample_size = len(data)\n",
    "    sample_mean = np.mean(data)\n",
    "    \n",
    "    outliers = []\n",
    "    for value in data:\n",
    "        p_value = z_test_p_value(value, population_mean, population_std, sample_size)\n",
    "        if p_value <= threshold:  # Flag as outlier if p-value is smaller than threshold\n",
    "            outliers.append(value)\n",
    "    \n",
    "    return outliers\n",
    "\n",
    "# T-test function (as previously provided)\n",
    "def t_test_p_value(sample_mean, population_mean, sample_std, sample_size, alternative='two-sided'):\n",
    "    t_stat = (sample_mean - population_mean) / (sample_std / math.sqrt(sample_size))\n",
    "    degrees_of_freedom = sample_size - 1\n",
    "    if alternative == 'two-sided':\n",
    "        p_value = 2 * (1 - t.cdf(abs(t_stat), df=degrees_of_freedom))\n",
    "    elif alternative == 'greater':\n",
    "        p_value = 1 - t.cdf(t_stat, df=degrees_of_freedom)\n",
    "    elif alternative == 'less':\n",
    "        p_value = t.cdf(t_stat, df=degrees_of_freedom)\n",
    "    else:\n",
    "        raise ValueError(\"Alternative must be one of ['two-sided', 'greater', 'less']\")\n",
    "    \n",
    "    return p_value\n",
    "\n",
    "# Function to flag outliers using T-test\n",
    "def detect_outliers_t(data, population_mean, sample_std, threshold=0.05):\n",
    "    sample_size = len(data)\n",
    "    sample_mean = np.mean(data)\n",
    "    \n",
    "    outliers = []\n",
    "    for value in data:\n",
    "        p_value = t_test_p_value(value, population_mean, sample_std, sample_size)\n",
    "        if p_value <= threshold:  # Flag as outlier if p-value is smaller than threshold\n",
    "            outliers.append(value)\n",
    "    \n",
    "    return outliers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Domains in training set: ['Other' 'Humanities/Social Science' 'Math' 'Physics'\n",
      " 'Computer Science/AI' 'Biology/Medicine' 'Chemistry' 'Engineering']\n",
      "Domains in evaluation set: ['Other' 'Humanities/Social Science' 'Math' 'Physics'\n",
      " 'Computer Science/AI' 'Biology/Medicine' 'Chemistry' 'Engineering']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Domain</th>\n",
       "      <th>Total</th>\n",
       "      <th>Train</th>\n",
       "      <th>Eval</th>\n",
       "      <th>Train %</th>\n",
       "      <th>Eval %</th>\n",
       "      <th>Train/Eval Ratio</th>\n",
       "      <th>Imbalance Severity</th>\n",
       "      <th>Sufficient Data</th>\n",
       "      <th>P-Value</th>\n",
       "      <th>Test Score</th>\n",
       "      <th>DOF</th>\n",
       "      <th>Expected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Math</td>\n",
       "      <td>1106</td>\n",
       "      <td>774</td>\n",
       "      <td>332</td>\n",
       "      <td>0.699819</td>\n",
       "      <td>0.300181</td>\n",
       "      <td>2.331325</td>\n",
       "      <td>0.100181</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>[[774.0, 332.0], [774.0, 332.0]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Biology/Medicine</td>\n",
       "      <td>303</td>\n",
       "      <td>212</td>\n",
       "      <td>91</td>\n",
       "      <td>0.699670</td>\n",
       "      <td>0.300330</td>\n",
       "      <td>2.329670</td>\n",
       "      <td>0.100330</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>[[212.0, 91.0], [212.0, 91.0]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Other</td>\n",
       "      <td>258</td>\n",
       "      <td>180</td>\n",
       "      <td>78</td>\n",
       "      <td>0.697674</td>\n",
       "      <td>0.302326</td>\n",
       "      <td>2.307692</td>\n",
       "      <td>0.102326</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>[[180.0, 78.0], [180.0, 78.0]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Computer Science/AI</td>\n",
       "      <td>258</td>\n",
       "      <td>180</td>\n",
       "      <td>78</td>\n",
       "      <td>0.697674</td>\n",
       "      <td>0.302326</td>\n",
       "      <td>2.307692</td>\n",
       "      <td>0.102326</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>[[180.0, 78.0], [180.0, 78.0]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Physics</td>\n",
       "      <td>240</td>\n",
       "      <td>168</td>\n",
       "      <td>72</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>[[168.0, 72.0], [168.0, 72.0]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Humanities/Social Science</td>\n",
       "      <td>235</td>\n",
       "      <td>164</td>\n",
       "      <td>71</td>\n",
       "      <td>0.697872</td>\n",
       "      <td>0.302128</td>\n",
       "      <td>2.309859</td>\n",
       "      <td>0.102128</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>[[164.0, 71.0], [164.0, 71.0]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Chemistry</td>\n",
       "      <td>170</td>\n",
       "      <td>119</td>\n",
       "      <td>51</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>[[119.0, 51.0], [119.0, 51.0]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Engineering</td>\n",
       "      <td>130</td>\n",
       "      <td>91</td>\n",
       "      <td>39</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>[[91.0, 39.0], [91.0, 39.0]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Domain  Total  Train  Eval   Train %    Eval %  \\\n",
       "0                       Math   1106    774   332  0.699819  0.300181   \n",
       "1           Biology/Medicine    303    212    91  0.699670  0.300330   \n",
       "2                      Other    258    180    78  0.697674  0.302326   \n",
       "3        Computer Science/AI    258    180    78  0.697674  0.302326   \n",
       "4                    Physics    240    168    72  0.700000  0.300000   \n",
       "5  Humanities/Social Science    235    164    71  0.697872  0.302128   \n",
       "6                  Chemistry    170    119    51  0.700000  0.300000   \n",
       "7                Engineering    130     91    39  0.700000  0.300000   \n",
       "\n",
       "   Train/Eval Ratio  Imbalance Severity  Sufficient Data  P-Value  Test Score  \\\n",
       "0          2.331325            0.100181             True      1.0         0.0   \n",
       "1          2.329670            0.100330             True      1.0         0.0   \n",
       "2          2.307692            0.102326             True      1.0         0.0   \n",
       "3          2.307692            0.102326             True      1.0         0.0   \n",
       "4          2.333333            0.100000             True      1.0         0.0   \n",
       "5          2.309859            0.102128             True      1.0         0.0   \n",
       "6          2.333333            0.100000             True      1.0         0.0   \n",
       "7          2.333333            0.100000             True      1.0         0.0   \n",
       "\n",
       "   DOF                          Expected  \n",
       "0    1  [[774.0, 332.0], [774.0, 332.0]]  \n",
       "1    1    [[212.0, 91.0], [212.0, 91.0]]  \n",
       "2    1    [[180.0, 78.0], [180.0, 78.0]]  \n",
       "3    1    [[180.0, 78.0], [180.0, 78.0]]  \n",
       "4    1    [[168.0, 72.0], [168.0, 72.0]]  \n",
       "5    1    [[164.0, 71.0], [164.0, 71.0]]  \n",
       "6    1    [[119.0, 51.0], [119.0, 51.0]]  \n",
       "7    1      [[91.0, 39.0], [91.0, 39.0]]  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Validate expected column\n",
    "if domain_col not in df.columns:\n",
    "  raise ValueError(f\"Expected column '{domain_col}' not found in dataset.\")\n",
    "\n",
    "# Overall domain distribution\n",
    "domain_counts = df[domain_col].value_counts().reset_index()\n",
    "domain_counts.columns = [domain_col, \"count\"]\n",
    "\n",
    "# Create a dictionary to hold train and eval sets for each domain\n",
    "df_train = pd.DataFrame()\n",
    "df_eval = pd.DataFrame()\n",
    "\n",
    "# For each domain, split it such that it appears in both the training and evaluation sets\n",
    "for domain in df[domain_col].unique():\n",
    "  # Select all rows for the current domain\n",
    "  domain_data = df[df[domain_col] == domain]\n",
    "\n",
    "  # Split the domain data into train and eval sets\n",
    "  train_data, eval_data = train_test_split(domain_data, test_size=test_size, random_state=42)\n",
    "\n",
    "  # Append the data to the respective train and eval sets\n",
    "  df_train = pd.concat([df_train, train_data])\n",
    "  df_eval = pd.concat([df_eval, eval_data])\n",
    "\n",
    "# Check that both train and eval sets contain all domains\n",
    "print(\"Domains in training set:\", df_train[domain_col].unique())\n",
    "print(\"Domains in evaluation set:\", df_eval[domain_col].unique())\n",
    "\n",
    "# Training set distribution\n",
    "train_counts = df_train[domain_col].value_counts().reset_index()\n",
    "train_counts.columns = [domain_col, \"count\"]\n",
    "\n",
    "# Evaluation set distribution\n",
    "eval_counts = df_eval[domain_col].value_counts().reset_index()\n",
    "eval_counts.columns = [domain_col, \"count\"]\n",
    "\n",
    "# Detailed stats per domain\n",
    "# Step 1: Compute stats without chi-squared\n",
    "stats = []\n",
    "\n",
    "# Iterate over all domains to compute basic stats first\n",
    "for dom in domain_counts[domain_col]:\n",
    "    # Get counts for each domain in the train set\n",
    "    train_n = train_counts[train_counts[domain_col] == dom][\"count\"].values[0] if dom in train_counts[domain_col].values else 0\n",
    "    \n",
    "    # Get counts for each domain in the eval set\n",
    "    eval_n = eval_counts[eval_counts[domain_col] == dom][\"count\"].values[0] if dom in eval_counts[domain_col].values else 0\n",
    "    \n",
    "    # Ensure total counts are correct\n",
    "    total_n = train_n + eval_n\n",
    "    \n",
    "    # Sufficient data check\n",
    "    sufficiency = total_n >= min_count_per_domain\n",
    "    \n",
    "    # Imbalance ratio\n",
    "    imbalance_ratio = train_n / total_n if total_n > 0 else 0\n",
    "    \n",
    "    # Eval ratio\n",
    "    eval_ratio = eval_n / total_n if total_n > 0 else 0\n",
    "    \n",
    "    # Train/Eval ratio\n",
    "    train_eval_ratio = train_n / eval_n if eval_n > 0 else float(\"inf\")\n",
    "    \n",
    "    # Imbalance severity\n",
    "    imbalance_severity = abs(0.8 - imbalance_ratio)  # Deviation from ideal split\n",
    "    \n",
    "    # Append the domain stats for now, without chi-squared results\n",
    "    stats.append({\n",
    "        \"Domain\": dom, \"Total\": total_n, \"Train\": train_n, \"Eval\": eval_n, \n",
    "        \"Train %\": imbalance_ratio, \"Eval %\": eval_ratio, \"Train/Eval Ratio\": train_eval_ratio,\n",
    "        \"Imbalance Severity\": imbalance_severity, \"Sufficient Data\": sufficiency\n",
    "    })\n",
    "\n",
    "# Step 2: Perform Chi-Squared Calculation on valid domains\n",
    "chi2_results = []\n",
    "for stat in stats:\n",
    "    train_n = stat[\"Train\"]\n",
    "    eval_n = stat[\"Eval\"]\n",
    "    \n",
    "    test, p_value, dof, expected = ????????????\n",
    "    \n",
    "    # Add chi-squared results to the domain stats\n",
    "    chi2_results.append({\n",
    "        \"Domain\": stat[\"Domain\"], \"P-Value\": p_value, \"Test Score\": test, \"DOF\": dof, \"Expected\": expected\n",
    "    })\n",
    "\n",
    "# Step 3: Combine the stats and chi-squared results\n",
    "df_stats = pd.DataFrame(stats)\n",
    "df_chi2 = pd.DataFrame(chi2_results)\n",
    "\n",
    "# Merge both stats and chi-squared results\n",
    "df_stats = df_stats.merge(df_chi2, on=\"Domain\", how=\"left\")\n",
    "\n",
    "\n",
    "# Display the stats\n",
    "df_stats"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
